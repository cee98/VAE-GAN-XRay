class Encoder(nn.Module):

    """
    Encoder network for VAE.

    This class defines the architecture of the encoder network, which takes an input tensor and produces
    the mean and log variance of the latent space.

    Attributes:
        conv1 (nn.Conv2d): First convolutional layer with 1 input channel and 128 output channels.
        bn1 (nn.BatchNorm2d): Batch normalization layer after the first convolution.
        conv2 (nn.Conv2d): Second convolutional layer with 128 input channels and 128 output channels.
        bn2 (nn.BatchNorm2d): Batch normalization layer after the second convolution.
        conv3 (nn.Conv2d): Third convolutional layer with 128 input channels and 256 output channels.
        bn3 (nn.BatchNorm2d): Batch normalization layer after the third convolution.
        relu (nn.LeakyReLU): Leaky ReLU activation function with a negative slope of 0.2.
        fc1 (nn.Linear): Fully connected layer with 256*16*16 input features and 2048 output features.
        bn4 (nn.BatchNorm1d): Batch normalization layer after the fully connected layer.
        fc_mean (nn.Linear): Fully connected layer to compute the mean of the latent space (128-dimensional).
        fc_log_variance (nn.Linear): Fully connected layer to compute the log variance of the latent space (128-dimensional).

    Methods:
        forward(x): Forward pass through the encoder network.

    Returns:
        Tuple[torch.Tensor, torch.Tensor]: A tuple containing the mean and log variance of the latent space.
    """


    def __init__(self):
        super(Encoder, self).__init__()
        # in_channels=1
        self.conv1 = nn.Conv2d(1, 128, 5, padding=2, stride=2)
        self.bn1 = nn.BatchNorm2d(128, momentum=0.9)
        self.conv2 = nn.Conv2d(128, 128, 5, padding=2, stride=2)
        self.bn2 = nn.BatchNorm2d(128, momentum=0.9)
        self.conv3 = nn.Conv2d(128, 256, 5, padding=2, stride=2)
        self.bn3 = nn.BatchNorm2d(256, momentum=0.9)
        self.relu = nn.LeakyReLU(0.2)
        self.fc1 = nn.Linear(256 * 16 * 16, 2048)
        self.bn4 = nn.BatchNorm1d(2048, momentum=0.9)
        self.fc_mean = nn.Linear(2048, 128)
        #latent dim=128
        self.fc_log_variance = nn.Linear(2048, 128)

    def forward(self, x):

        """
        Forward pass of the encoder network.

        Args:
            x (torch.Tensor): Input tensor, typically an image.

        Returns:
            mean (torch.Tensor): Mean of the latent space distribution.
            log_variance (torch.Tensor): Log variance of the latent space distribution.
        """

        batch_size = x.size()[0]
        out = self.relu(self.bn1(self.conv1(x)))
        out = self.relu(self.bn2(self.conv2(out)))
        out = self.relu(self.bn3(self.conv3(out)))
        out = out.view(batch_size, -1)
        out = self.relu(self.bn4(self.fc1(out)))
        mean = self.fc_mean(out)
        log_variance = self.fc_log_variance(out)

        return mean, log_variance
